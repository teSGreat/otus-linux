# проверка_кластера

Предполагаем, что на машине уже установлен docker и инициализирован swarm.

Запускаем деплой, при этом docker нужные образы выкачает автоматически
```bash
[root@docker innodb]# docker stack deploy --with-registry-auth -c docker-compose_swarm_prod.yml percona-mysql8-innodb
Creating network percona-mysql8-innodb_swarm-mysql-nosysd-net
Creating service percona-mysql8-innodb_mysql03
Creating service percona-mysql8-innodb_mysqlrouter
Creating service percona-mysql8-innodb_mysql01
Creating service percona-mysql8-innodb_mysql02
```
Заметил нюанс, что при просмотре списка локальных образов не отображается тэг "swarm"
```bash
[root@docker ~]# docker images
REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
timlok/mysqlrouter-nosysd   <none>              18298847374a        7 hours ago         366MB
timlok/mysql01-nosysd       <none>              e305bfb2e00b        28 hours ago        840MB
timlok/mysql02-nosysd       <none>              afbf40c8501b        28 hours ago        840MB
timlok/mysql03-nosysd       <none>              15bc07a6310a        28 hours ago        840MB
timlok/mysqlrouter-cl       v3                  e1e88e0c02c0        3 days ago          273MB
timlok/mysql03-cl           v3                  2c99af418669        3 days ago          1.02GB
timlok/mysql02-cl           v3                  9d8b63aa0bc7        3 days ago          1.02GB
timlok/mysql01-cl           v3                  0c8673aa4be5        3 days ago          1.02GB
```
Проверяем, что сервис запустился
```bash
[root@docker ~]# docker stack services percona-mysql8-innodb
ID                  NAME                                MODE                REPLICAS            IMAGE                             PORTS
03uqt0fcyf1n        percona-mysql8-innodb_mysql02       replicated          1/1                 timlok/mysql02-nosysd:swarm
gfg55mny9y2v        percona-mysql8-innodb_mysqlrouter   replicated          1/1                 timlok/mysqlrouter-nosysd:swarm   *:6446-6447->6446-6447/tcp, *:64460->64460/tcp, *:64470->64470/tcp
ob9x6tk94dsz        percona-mysql8-innodb_mysql03       replicated          1/1                 timlok/mysql03-nosysd:swarm
vjt8cvrn8eeg        percona-mysql8-innodb_mysql01       replicated          1/1                 timlok/mysql01-nosysd:swarm
```
Проверяем, что контейнер с mysqlrouter успешно переконфигурировал кластер
```bash
[root@docker ~]# docker logs -t -f percona-mysql8-innodb_mysqlrouter.1.rdmw80625o50y4d9xktiwicv1
2019-09-17T12:56:42.324553639Z
2019-09-17T12:56:42.324586974Z #########################################################
2019-09-17T12:56:42.324590868Z ##### The cluster reconfiguration script is running #####
2019-09-17T12:56:42.324593153Z #########################################################
2019-09-17T12:56:42.324595398Z
2019-09-17T12:56:42.324597548Z Waiting 120 seconds before starting work
2019-09-17T12:56:42.324599818Z
2019-09-17T12:58:41.554169489Z WARNING: Using a password on the command line interface can be insecure.
2019-09-17T12:58:41.760781537Z Reconfiguring the default cluster from complete outage...
2019-09-17T12:58:42.239292916Z
2019-09-17T12:58:42.239333056Z The instance 'mysql02:3306' was part of the cluster configuration.
2019-09-17T12:58:42.239341442Z
2019-09-17T12:58:42.239346322Z The instance 'mysql03:3306' was part of the cluster configuration.
2019-09-17T12:58:42.239351131Z
2019-09-17T12:58:56.498907756Z
2019-09-17T12:58:56.498944034Z The cluster was successfully rebooted.
2019-09-17T12:58:56.498949642Z
2019-09-17T12:58:56.516363104Z Fine! mysql01 is RW
2019-09-17T12:59:00.530509653Z #########################################################
2019-09-17T12:59:00.530595883Z #####   Cluster reconfiguration script completed    #####
2019-09-17T12:59:00.530617620Z #####             SCRIPT EXIT CODE = 0              #####
2019-09-17T12:59:00.530632349Z #####               RW SERVER mysql01               #####
2019-09-17T12:59:00.530646472Z #########################################################
2019-09-17T12:59:00.530660259Z
2019-09-17T12:59:00.552251955Z Loading all plugins.
2019-09-17T12:59:00.552302268Z   plugin 'logger:' loading
2019-09-17T12:59:00.552312614Z   plugin 'metadata_cache:TestCluster' loading
2019-09-17T12:59:00.553582206Z   plugin 'routing:TestCluster_default_ro' loading
2019-09-17T12:59:00.555181380Z   plugin 'routing:TestCluster_default_rw' loading
2019-09-17T12:59:00.555240733Z   plugin 'routing:TestCluster_default_x_ro' loading
2019-09-17T12:59:00.555250544Z   plugin 'routing:TestCluster_default_x_rw' loading
2019-09-17T12:59:00.555257319Z Initializing all plugins.
2019-09-17T12:59:00.555530699Z   plugin 'logger' initializing
2019-09-17T12:59:00.556898364Z logging facility initialized, switching logging to loggers specified in configuration
```
Логинимся, например, в контейнер mysql02 и проверяем статус кластера
```bash
[root@docker /]# docker exec -ti percona-mysql8-innodb_mysql02.1.li0kiq9btu9bpbr9ebgr07obk bash
```
```js
[root@mysql02 /]# mysqlsh --uri cladmin@mysql02:3306 -p'StrongPassword!#1' --cluster
MySQL Shell 8.0.15

Copyright (c) 2016, 2019, Oracle and/or its affiliates. All rights reserved.
Oracle is a registered trademark of Oracle Corporation and/or its affiliates.
Other names may be trademarks of their respective owners.

Type '\help' or '\?' for help; '\quit' to exit.
WARNING: Using a password on the command line interface can be insecure.
Creating a session to 'cladmin@mysql02:3306'
Fetching schema names for autocompletion... Press ^C to stop.
Your MySQL connection id is 39
Server version: 8.0.16-7 Percona Server (GPL), Release 7, Revision 613e312
No default schema selected; type \use <schema> to set one.
You are connected to a member of cluster 'TestCluster'.
Variable 'cluster' is set.
Use cluster.status() in scripting mode to get status of this cluster or cluster.help() for more commands.

 MySQL  mysql02:3306 ssl  JS > cluster.status()
{
    "clusterName": "TestCluster", 
    "defaultReplicaSet": {
        "name": "default", 
        "primary": "mysql01:3306", 
        "ssl": "REQUIRED", 
        "status": "OK", 
        "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", 
        "topology": {
            "mysql01:3306": {
                "address": "mysql01:3306", 
                "mode": "R/W", 
                "readReplicas": {}, 
                "role": "HA", 
                "status": "ONLINE"
            }, 
            "mysql02:3306": {
                "address": "mysql02:3306", 
                "mode": "R/O", 
                "readReplicas": {}, 
                "role": "HA", 
                "status": "ONLINE"
            }, 
            "mysql03:3306": {
                "address": "mysql03:3306", 
                "mode": "R/O", 
                "readReplicas": {}, 
                "role": "HA", 
                "status": "ONLINE"
            }
        }, 
        "topologyMode": "Single-Primary"
    }, 
    "groupInformationSourceMember": "mysql01:3306"
}
```
И в этом же контейнере посмотрим логи mysql
```bash
[root@mysql02 /]# tail -n 25 /var/log/mysqld.log 
2019-09-16T11:02:49.436227Z 22 [Warning] [MY-010897] [Repl] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information.
2019-09-16T11:02:49.511025Z 22 [System] [MY-010562] [Repl] Slave I/O thread for channel 'group_replication_recovery': connected to master 'mysql_innodb_cluster_r0431341467@mysql01:3306',replication started in log 'FIRST' at position 4
2019-09-16T11:02:49.818970Z 20 [System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='mysql01', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='<NULL>', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''.
2019-09-16T12:21:19.785144Z 0 [System] [MY-010910] [Server] /usr/sbin/mysqld: Shutdown complete (mysqld 8.0.16-7)  Percona Server (GPL), Release 7, Revision 613e312.
2019-09-17T12:56:34.531366Z 0 [System] [MY-010116] [Server] /usr/sbin/mysqld (mysqld 8.0.16-7) starting as process 1
2019-09-17T12:56:34.939674Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.
2019-09-17T12:56:34.967777Z 0 [Warning] [MY-010604] [Repl] Neither --relay-log nor --relay-log-index were used; so replication may break when this MySQL server acts as a slave and has his hostname changed!! Please use '--relay-log=mysql02-relay-bin' to avoid this problem.
2019-09-17T12:56:34.979235Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.16-7'  socket: '/var/lib/mysql/mysql.sock'  port: 3306  Percona Server (GPL), Release 7, Revision 613e312.
2019-09-17T12:56:35.114523Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Socket: '/var/lib/mysql/mysqlx.sock' bind-address: '::' port: 33060
2019-09-17T12:56:39.958357Z 2 [Warning] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Peer address "mysql01:33061" is not valid.'
2019-09-17T12:56:39.958458Z 2 [Warning] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Peer address "mysql03:33061" is not valid.'
2019-09-17T12:56:39.958493Z 2 [ERROR] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] None of the provided peer address is valid.'
2019-09-17T12:56:39.959486Z 2 [ERROR] [MY-011674] [Repl] Plugin group_replication reported: 'Unable to initialize the group communication engine'
2019-09-17T12:56:39.959552Z 2 [ERROR] [MY-011637] [Repl] Plugin group_replication reported: 'Error on group communication engine initialization'
2019-09-17T12:56:39.959608Z 2 [ERROR] [MY-011718] [Repl] Plugin group_replication reported: 'Error calling group communication interfaces while trying to leave the group'
2019-09-17T12:58:41.961445Z 10 [Warning] [MY-010055] [Server] IP address '172.20.20.4' could not be resolved: Name or service not known
mbind: Operation not permitted
mbind: Operation not permitted
2019-09-17T12:58:47.947732Z 19 [Warning] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Automatically adding IPv4 localhost address to the whitelist. It is mandatory that it is added.'
2019-09-17T12:58:47.947774Z 19 [Warning] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Automatically adding IPv6 localhost address to the whitelist. It is mandatory that it is added.'
2019-09-17T12:58:47.949746Z 21 [System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_applier' executed'. Previous state master_host='<NULL>', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='<NULL>', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''.
2019-09-17T12:58:51.744223Z 27 [System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='<NULL>', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='mysql01', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''.
2019-09-17T12:58:51.757980Z 28 [Warning] [MY-010897] [Repl] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information.
2019-09-17T12:58:51.778211Z 28 [System] [MY-010562] [Repl] Slave I/O thread for channel 'group_replication_recovery': connected to master 'mysql_innodb_cluster_r0431341467@mysql01:3306',replication started in log 'FIRST' at position 4
2019-09-17T12:58:51.847718Z 27 [System] [MY-010597] [Repl] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='mysql01', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='<NULL>', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''.
```
На хосте с докером проверям проброшенные порты контейнера с mysqlrouter
```bash
[root@docker ~]# netstat -lptun | grep dockerd
tcp6       0      0 :::2377                 :::*                    LISTEN      817/dockerd         
tcp6       0      0 :::7946                 :::*                    LISTEN      817/dockerd         
tcp6       0      0 :::64460                :::*                    LISTEN      817/dockerd         
tcp6       0      0 :::6446                 :::*                    LISTEN      817/dockerd         
tcp6       0      0 :::6447                 :::*                    LISTEN      817/dockerd         
tcp6       0      0 :::64470                :::*                    LISTEN      817/dockerd         
udp6       0      0 :::7946                 :::*                                817/dockerd 
```
С хоста с докером подключаемся к кластеру
```bash
[root@docker ~]# mysql -ucladmin -p'StrongPassword!#1' -h127.0.0.1 -P6446
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2317
Server version: 8.0.16-7 Percona Server (GPL), Release 7, Revision 613e312

Copyright (c) 2009-2019 Percona LLC and/or its affiliates
Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql>
```
и успешно создаём пользователя otus
```sql
mysql -ucladmin -p'StrongPassword!#1' -h127.0.0.1 -P6446 -e "create user 'otus'@'%' identified by '0tusPass*';"

[root@docker ~]# mysql -ucladmin -p'StrongPassword!#1' -h127.0.0.1 -P6446 -e "select user,host from mysql.user;"
mysql: [Warning] Using a password on the command line interface can be insecure.
+----------------------------------+---------------------------+
| user                             | host                      |
+----------------------------------+---------------------------+
| cladmin                          | %                         |
| mysql_router1_tz66l8hsenqu       | %                         |
| otus                             | %                         |
| mysql_innodb_cluster_r0431085013 | 172.20.20.0/255.255.255.0 |
| mysql_innodb_cluster_r0431341467 | 172.20.20.0/255.255.255.0 |
| mysql_innodb_cluster_r0431431497 | 172.20.20.0/255.255.255.0 |
| mysql_innodb_cluster_r0431458225 | 172.20.20.0/255.255.255.0 |
| mysql.infoschema                 | localhost                 |
| mysql.session                    | localhost                 |
| mysql.sys                        | localhost                 |
| root                             | localhost                 |
+----------------------------------+---------------------------+
```

